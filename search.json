[{"title":"爬虫相关概念","url":"https://vbozhang.github.io/2021/02/02/python-crawler/basics/","content":"决定系统学习下网络爬虫，这是这个系列的第一篇，主要是爬虫相关的一些概念的介绍\n\n 网络爬虫\n 什么是网络爬虫\n网络爬虫，又被称为网页蜘蛛，网络机器人，在FOAF（FOAF，即Friend-of-a-Friend，简称FOAF。FOAF 是一种 XML/RDF 词汇表，它以计算机可读的形式描述您通常可能放在主 Web 页面上的个人信息之类的信息）社区中间，更经常的称为网页追逐者，是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本，另外一些不常使用的名字还有蚂蚁、自动索引、模拟程序或者蠕虫。\n\n更通俗一点说\n爬虫就是一个探测机器，它的基本操作就是模拟人的行为去各个网站溜达，点点按钮，查查数据，或者把看到的信息背回来。就像一只虫子在一幢楼里不知疲倦地爬来爬去。\n你可以简单地想象：每个爬虫都是你的「分身」。就像孙悟空拔了一撮汗毛，吹出一堆猴子一样。\n你每天使用的百度，其实就是利用了这种爬虫技术：每天放出无数爬虫到各个网站，把他们的信息抓回来，然后化好淡妆排着小队等你来检索。\n抢票软件，就相当于撒出去无数个分身，每一个分身都帮助你不断刷新 12306 网站的火车余票。一旦发现有票，就马上拍下来，然后对你喊：土豪快来付款。\n\n 网络爬虫的分类\n根据使用场景，爬虫可以分为通用爬虫和聚焦爬虫\n\n通用爬虫：通用爬虫是搜索引擎抓取系统（百度、谷歌、搜狗等）的重要组成部分。主要是将互联网上的网页下载到本地，形成一个互联网内容的镜像备份。\n聚焦爬虫：是面向特定需求的一种网络爬虫程序，他与通用爬虫的区别在于：聚焦爬虫在实施网页抓取的时候会对内容进行筛选和处理，尽量保证只抓取与需求相关的网页信息。\n\n 为什么用python写网络爬虫\n爬虫是工具性程序，对速度和效率要求高，PHP对对线程、异步支持不是很好，并发处理能力弱；JAVA语言笨重，代码量大，重构成本高；C/C++学习和开发成本高；Python代码简洁，支持模块多，开发效率高，易于修改，适合作为开发爬虫的语言。\n\n参考：\n[1]&quot;通俗的讲，网络爬虫到底是什么？&quot;知乎.史中https://www.zhihu.com/question/24098641/answer/453634446\n[2]\n","categories":["python爬虫"],"tags":["python","http协议","网络爬虫"]}]